{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "You'll clean, explore, and model this dataset with a multivariate linear regression to predict the sale price of houses as accurately as possible.\n",
    "\n",
    "Please fill out:\n",
    "* Student name: Caitlin Snyder\n",
    "* Student pace: self-paced\n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: Jeff Herman\n",
    "* Blog post URL: https://caitlinsnyder.medium.com/exploring-king-county-housing-data-4b8f28ae0853\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I wrap up Module 2 of Flat Iron's Data Science bootcamp, I will be conducting multiple linear regression on a subset of the King County Housing Sale Price dataset. I've referenced the \n",
    "[King County Realtor Glossary](https://info.kingcounty.gov/assessor/esales/Glossary.aspx?type=r) to interpret the feature names included in the dataset. Follow along below, or take a look at the [Jupyter notebook]()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To guide my analysis, I began by asking three questions that were of interest to me as I read through the King County Realtor Glossary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) What is the effect on sale price of classification as a low grade* property?\n",
    "\n",
    "2) What is the effect on sale price of classification as a high condition* property?\n",
    "\n",
    "3) What is the effect on sale price of having a waterfront?\n",
    "\n",
    "**as defined by the [King County Assesor's Office](https://kingcounty.gov/depts/assessor/~/media/depts/Assessor/documents/AreaReports/2019/Residential/015.ashx)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll try to answer these questions using multiple linear regression--let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Import the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the relevant libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and preview the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>10/13/2014</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>2/25/2015</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>2/18/2015</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  10/13/2014  221900.0         3       1.00         1180   \n",
       "1  6414100192   12/9/2014  538000.0         3       2.25         2570   \n",
       "2  5631500400   2/25/2015  180000.0         2       1.00          770   \n",
       "3  2487200875   12/9/2014  604000.0         4       3.00         1960   \n",
       "4  1954400510   2/18/2015  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0         NaN   0.0  ...      7        1180            0.0   \n",
       "1      7242     2.0         0.0   0.0  ...      7        2170          400.0   \n",
       "2     10000     1.0         0.0   0.0  ...      6         770            0.0   \n",
       "3      5000     1.0         0.0   0.0  ...      7        1050          910.0   \n",
       "4      8080     1.0         0.0   0.0  ...      8        1680            0.0   \n",
       "\n",
       "  yr_built  yr_renovated  zipcode      lat     long  sqft_living15  sqft_lot15  \n",
       "0     1955           0.0    98178  47.5112 -122.257           1340        5650  \n",
       "1     1951        1991.0    98125  47.7210 -122.319           1690        7639  \n",
       "2     1933           NaN    98028  47.7379 -122.233           2720        8062  \n",
       "3     1965           0.0    98136  47.5208 -122.393           1360        5000  \n",
       "4     1987           0.0    98074  47.6168 -122.045           1800        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('kc_house_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the data, we see that we have 15429 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21597, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "# (21597, 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call describe() on the dataframe to get an overview of the descriptive statistics corresponding to each attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.159700e+04</td>\n",
       "      <td>2.159700e+04</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>2.159700e+04</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>19221.000000</td>\n",
       "      <td>21534.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>17755.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.580474e+09</td>\n",
       "      <td>5.402966e+05</td>\n",
       "      <td>3.373200</td>\n",
       "      <td>2.115826</td>\n",
       "      <td>2080.321850</td>\n",
       "      <td>1.509941e+04</td>\n",
       "      <td>1.494096</td>\n",
       "      <td>0.007596</td>\n",
       "      <td>0.233863</td>\n",
       "      <td>3.409825</td>\n",
       "      <td>7.657915</td>\n",
       "      <td>1788.596842</td>\n",
       "      <td>1970.999676</td>\n",
       "      <td>83.636778</td>\n",
       "      <td>98077.951845</td>\n",
       "      <td>47.560093</td>\n",
       "      <td>-122.213982</td>\n",
       "      <td>1986.620318</td>\n",
       "      <td>12758.283512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.876736e+09</td>\n",
       "      <td>3.673681e+05</td>\n",
       "      <td>0.926299</td>\n",
       "      <td>0.768984</td>\n",
       "      <td>918.106125</td>\n",
       "      <td>4.141264e+04</td>\n",
       "      <td>0.539683</td>\n",
       "      <td>0.086825</td>\n",
       "      <td>0.765686</td>\n",
       "      <td>0.650546</td>\n",
       "      <td>1.173200</td>\n",
       "      <td>827.759761</td>\n",
       "      <td>29.375234</td>\n",
       "      <td>399.946414</td>\n",
       "      <td>53.513072</td>\n",
       "      <td>0.138552</td>\n",
       "      <td>0.140724</td>\n",
       "      <td>685.230472</td>\n",
       "      <td>27274.441950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000102e+06</td>\n",
       "      <td>7.800000e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>5.200000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98001.000000</td>\n",
       "      <td>47.155900</td>\n",
       "      <td>-122.519000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>651.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.123049e+09</td>\n",
       "      <td>3.220000e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1430.000000</td>\n",
       "      <td>5.040000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1951.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98033.000000</td>\n",
       "      <td>47.471100</td>\n",
       "      <td>-122.328000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.904930e+09</td>\n",
       "      <td>4.500000e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1910.000000</td>\n",
       "      <td>7.618000e+03</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1560.000000</td>\n",
       "      <td>1975.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98065.000000</td>\n",
       "      <td>47.571800</td>\n",
       "      <td>-122.231000</td>\n",
       "      <td>1840.000000</td>\n",
       "      <td>7620.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.308900e+09</td>\n",
       "      <td>6.450000e+05</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>1.068500e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2210.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98118.000000</td>\n",
       "      <td>47.678000</td>\n",
       "      <td>-122.125000</td>\n",
       "      <td>2360.000000</td>\n",
       "      <td>10083.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.900000e+09</td>\n",
       "      <td>7.700000e+06</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13540.000000</td>\n",
       "      <td>1.651359e+06</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9410.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>98199.000000</td>\n",
       "      <td>47.777600</td>\n",
       "      <td>-121.315000</td>\n",
       "      <td>6210.000000</td>\n",
       "      <td>871200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         price      bedrooms     bathrooms   sqft_living  \\\n",
       "count  2.159700e+04  2.159700e+04  21597.000000  21597.000000  21597.000000   \n",
       "mean   4.580474e+09  5.402966e+05      3.373200      2.115826   2080.321850   \n",
       "std    2.876736e+09  3.673681e+05      0.926299      0.768984    918.106125   \n",
       "min    1.000102e+06  7.800000e+04      1.000000      0.500000    370.000000   \n",
       "25%    2.123049e+09  3.220000e+05      3.000000      1.750000   1430.000000   \n",
       "50%    3.904930e+09  4.500000e+05      3.000000      2.250000   1910.000000   \n",
       "75%    7.308900e+09  6.450000e+05      4.000000      2.500000   2550.000000   \n",
       "max    9.900000e+09  7.700000e+06     33.000000      8.000000  13540.000000   \n",
       "\n",
       "           sqft_lot        floors    waterfront          view     condition  \\\n",
       "count  2.159700e+04  21597.000000  19221.000000  21534.000000  21597.000000   \n",
       "mean   1.509941e+04      1.494096      0.007596      0.233863      3.409825   \n",
       "std    4.141264e+04      0.539683      0.086825      0.765686      0.650546   \n",
       "min    5.200000e+02      1.000000      0.000000      0.000000      1.000000   \n",
       "25%    5.040000e+03      1.000000      0.000000      0.000000      3.000000   \n",
       "50%    7.618000e+03      1.500000      0.000000      0.000000      3.000000   \n",
       "75%    1.068500e+04      2.000000      0.000000      0.000000      4.000000   \n",
       "max    1.651359e+06      3.500000      1.000000      4.000000      5.000000   \n",
       "\n",
       "              grade    sqft_above      yr_built  yr_renovated       zipcode  \\\n",
       "count  21597.000000  21597.000000  21597.000000  17755.000000  21597.000000   \n",
       "mean       7.657915   1788.596842   1970.999676     83.636778  98077.951845   \n",
       "std        1.173200    827.759761     29.375234    399.946414     53.513072   \n",
       "min        3.000000    370.000000   1900.000000      0.000000  98001.000000   \n",
       "25%        7.000000   1190.000000   1951.000000      0.000000  98033.000000   \n",
       "50%        7.000000   1560.000000   1975.000000      0.000000  98065.000000   \n",
       "75%        8.000000   2210.000000   1997.000000      0.000000  98118.000000   \n",
       "max       13.000000   9410.000000   2015.000000   2015.000000  98199.000000   \n",
       "\n",
       "                lat          long  sqft_living15     sqft_lot15  \n",
       "count  21597.000000  21597.000000   21597.000000   21597.000000  \n",
       "mean      47.560093   -122.213982    1986.620318   12758.283512  \n",
       "std        0.138552      0.140724     685.230472   27274.441950  \n",
       "min       47.155900   -122.519000     399.000000     651.000000  \n",
       "25%       47.471100   -122.328000    1490.000000    5100.000000  \n",
       "50%       47.571800   -122.231000    1840.000000    7620.000000  \n",
       "75%       47.678000   -122.125000    2360.000000   10083.000000  \n",
       "max       47.777600   -121.315000    6210.000000  871200.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the data types, we see that both date and sqft_basement are stored as strings. We will need to address these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 int64\n",
       "date              object\n",
       "price            float64\n",
       "bedrooms           int64\n",
       "bathrooms        float64\n",
       "sqft_living        int64\n",
       "sqft_lot           int64\n",
       "floors           float64\n",
       "waterfront       float64\n",
       "view             float64\n",
       "condition          int64\n",
       "grade              int64\n",
       "sqft_above         int64\n",
       "sqft_basement     object\n",
       "yr_built           int64\n",
       "yr_renovated     float64\n",
       "zipcode            int64\n",
       "lat              float64\n",
       "long             float64\n",
       "sqft_living15      int64\n",
       "sqft_lot15         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n",
    "\n",
    "# id                 int64\n",
    "# date              object\n",
    "# price            float64\n",
    "# bedrooms           int64\n",
    "# bathrooms        float64\n",
    "# sqft_living        int64\n",
    "# sqft_lot           int64\n",
    "# floors           float64\n",
    "# waterfront       float64\n",
    "# view             float64\n",
    "# condition          int64\n",
    "# grade              int64\n",
    "# sqft_above         int64\n",
    "# sqft_basement     object\n",
    "# yr_built           int64\n",
    "# yr_renovated     float64\n",
    "# zipcode            int64\n",
    "# lat              float64\n",
    "# long             float64\n",
    "# sqft_living15      int64\n",
    "# sqft_lot15         int64\n",
    "# dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping irrelevant columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need 'id' for our analysis--we can drop this column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['id'], axis=1, inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset consists of 15429 rows. The total number  of records with null values (2376+63+454+3842=6735, or 44%) is currently far greater than 5%, meaning that simply dropping these records would likely significantly impact our analyses.\n",
    "\n",
    "Let's examine each attribute individiually to determine the appropriate course of action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                0\n",
       "price               0\n",
       "bedrooms            0\n",
       "bathrooms           0\n",
       "sqft_living         0\n",
       "sqft_lot            0\n",
       "floors              0\n",
       "waterfront       2376\n",
       "view               63\n",
       "condition           0\n",
       "grade               0\n",
       "sqft_above          0\n",
       "sqft_basement       0\n",
       "yr_built            0\n",
       "yr_renovated     3842\n",
       "zipcode             0\n",
       "lat                 0\n",
       "long                0\n",
       "sqft_living15       0\n",
       "sqft_lot15          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()\n",
    "\n",
    "# date                0\n",
    "# price               0\n",
    "# bedrooms            0\n",
    "# bathrooms           0\n",
    "# sqft_living         0\n",
    "# sqft_lot            0\n",
    "# floors              0\n",
    "# waterfront       2376\n",
    "# view               63\n",
    "# condition           0\n",
    "# grade               0\n",
    "# sqft_above          0\n",
    "# sqft_basement       0\n",
    "# yr_built            0\n",
    "# yr_renovated     3842\n",
    "# zipcode             0\n",
    "# lat                 0\n",
    "# long                0\n",
    "# sqft_living15       0\n",
    "# sqft_lot15          0\n",
    "# dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to decide how to handle null values in sqft_basement, waterfront, view, and yr_renovated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify and isolate the categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['waterfront', 'view', 'condition', 'grade', 'zipcode', 'date']\n",
    "df_cat = df[cat_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Date* is currently stored as strings. If we inspect the unique years, we see that only 2014 and 2015 are present in the data. We can simplify date to reflect only the relevant year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DatetimeIndex(pd.to_datetime(df_cat['date'])).year.unique()\n",
    "df_cat['date'] = pd.DatetimeIndex(pd.to_datetime(df['date'])).year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Waterfront* and *View* are both categorical features. Waterfront has 2376 missing values (roughly 15% of all records) while view has only 63. The great news is that we don't have much heavy lifting to do here--all we have to do is specify that our features will have nan values in our one-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = df_cat.astype('str')\n",
    "df_ohe = pd.get_dummies(df_cat, prefix=cat_features, dummy_na=True, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the continuous features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our continuous features are those that are not categorical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_features = [feat for feat in df.columns.tolist() if feat not in cat_features]\n",
    "df_cont = df[cont_features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to missing values, *Year renovated* contains a problematic value: 0. 0 does not make logical sense in this context. Let's replace these values with the median:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_median(df, col):\n",
    "    df_one_col = df[[col]]\n",
    "    df_one_col.fillna(df_one_col.median(), inplace=True)\n",
    "    df[col] = df_one_col[col]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont['yr_renovated'] = df_cont.apply(\n",
    "     lambda row: np.nan if row['yr_renovated'] == 0 else row['yr_renovated'],\n",
    "     axis=1)\n",
    "\n",
    "impute_median(df_cont, 'yr_renovated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values for *Basement square footage* are currently stored as strings--and these include question marks! We'll convert the entire column to numeric values, replacing nulls and question marks (missing values) with the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont['sqft_basement'] = df_cont.apply(\n",
    "     lambda row: np.nan if row['sqft_basement'] == '?' else float(row['sqft_basement']),\n",
    "     axis=1)\n",
    "\n",
    "impute_median(df_cont, 'sqft_basement')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can normalize our continuous values, we need to apply an offset to handle any negatives or 0s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def handle_zeros_pre_log(df, col):\n",
    "    no_zeros = df.loc[df[col] > 0]\n",
    "    col_min = no_zeros[col].min()\n",
    "    offset = col_min/2\n",
    "    df[col] = df.apply(\n",
    "        lambda row: row[col] + offset,\n",
    "        axis=1)\n",
    "    \n",
    "def handle_negatives_pre_log(df, col):\n",
    "    col_min = abs(df[col].min()) + 1\n",
    "    df[col] = df.apply(\n",
    "        lambda row: row[col] + col_min,\n",
    "        axis=1)\n",
    "\n",
    "handle_zeros_pre_log(df_cont, 'sqft_basement')\n",
    "handle_negatives_pre_log(df_cont, 'long')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And normalize!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log = np.log(df_cont)\n",
    "cont_features = [f'{column}_log' for column in df_cont.columns]\n",
    "df_log.columns = cont_features\n",
    "\n",
    "def normalize(feature):\n",
    "    return (feature - feature.mean()) / feature.std()\n",
    "\n",
    "df_log_norm = df_log.apply(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recombine features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll 'glue' our continuous and categorical features back together in a single dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_log</th>\n",
       "      <th>bedrooms_log</th>\n",
       "      <th>bathrooms_log</th>\n",
       "      <th>sqft_living_log</th>\n",
       "      <th>sqft_lot_log</th>\n",
       "      <th>floors_log</th>\n",
       "      <th>sqft_above_log</th>\n",
       "      <th>sqft_basement_log</th>\n",
       "      <th>yr_built_log</th>\n",
       "      <th>yr_renovated_log</th>\n",
       "      <th>...</th>\n",
       "      <th>zipcode_98166</th>\n",
       "      <th>zipcode_98168</th>\n",
       "      <th>zipcode_98177</th>\n",
       "      <th>zipcode_98178</th>\n",
       "      <th>zipcode_98188</th>\n",
       "      <th>zipcode_98198</th>\n",
       "      <th>zipcode_98199</th>\n",
       "      <th>zipcode_nan</th>\n",
       "      <th>date_2015</th>\n",
       "      <th>date_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.401998</td>\n",
       "      <td>-0.279718</td>\n",
       "      <td>-1.726509</td>\n",
       "      <td>-1.125556</td>\n",
       "      <td>-0.388430</td>\n",
       "      <td>-0.960852</td>\n",
       "      <td>-0.753565</td>\n",
       "      <td>-0.780762</td>\n",
       "      <td>-0.537409</td>\n",
       "      <td>0.047377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.279938</td>\n",
       "      <td>-0.279718</td>\n",
       "      <td>0.339653</td>\n",
       "      <td>0.709446</td>\n",
       "      <td>-0.113241</td>\n",
       "      <td>1.006831</td>\n",
       "      <td>0.672693</td>\n",
       "      <td>1.060276</td>\n",
       "      <td>-0.674325</td>\n",
       "      <td>-2.951470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.799430</td>\n",
       "      <td>-1.711611</td>\n",
       "      <td>-1.726509</td>\n",
       "      <td>-2.131893</td>\n",
       "      <td>0.244475</td>\n",
       "      <td>-0.960852</td>\n",
       "      <td>-1.752954</td>\n",
       "      <td>-0.780762</td>\n",
       "      <td>-1.293945</td>\n",
       "      <td>0.047377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.499698</td>\n",
       "      <td>0.736226</td>\n",
       "      <td>1.072635</td>\n",
       "      <td>0.070674</td>\n",
       "      <td>-0.523914</td>\n",
       "      <td>-0.960852</td>\n",
       "      <td>-1.026835</td>\n",
       "      <td>1.401732</td>\n",
       "      <td>-0.196338</td>\n",
       "      <td>0.047377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.178434</td>\n",
       "      <td>-0.279718</td>\n",
       "      <td>0.039555</td>\n",
       "      <td>-0.292725</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>-0.960852</td>\n",
       "      <td>0.073515</td>\n",
       "      <td>-0.780762</td>\n",
       "      <td>0.547946</td>\n",
       "      <td>0.047377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   price_log  bedrooms_log  bathrooms_log  sqft_living_log  sqft_lot_log  \\\n",
       "0  -1.401998     -0.279718      -1.726509        -1.125556     -0.388430   \n",
       "1   0.279938     -0.279718       0.339653         0.709446     -0.113241   \n",
       "2  -1.799430     -1.711611      -1.726509        -2.131893      0.244475   \n",
       "3   0.499698      0.736226       1.072635         0.070674     -0.523914   \n",
       "4   0.178434     -0.279718       0.039555        -0.292725      0.008139   \n",
       "\n",
       "   floors_log  sqft_above_log  sqft_basement_log  yr_built_log  \\\n",
       "0   -0.960852       -0.753565          -0.780762     -0.537409   \n",
       "1    1.006831        0.672693           1.060276     -0.674325   \n",
       "2   -0.960852       -1.752954          -0.780762     -1.293945   \n",
       "3   -0.960852       -1.026835           1.401732     -0.196338   \n",
       "4   -0.960852        0.073515          -0.780762      0.547946   \n",
       "\n",
       "   yr_renovated_log  ...  zipcode_98166  zipcode_98168  zipcode_98177  \\\n",
       "0          0.047377  ...            0.0            0.0            0.0   \n",
       "1         -2.951470  ...            0.0            0.0            0.0   \n",
       "2          0.047377  ...            0.0            0.0            0.0   \n",
       "3          0.047377  ...            0.0            0.0            0.0   \n",
       "4          0.047377  ...            0.0            0.0            0.0   \n",
       "\n",
       "   zipcode_98178  zipcode_98188  zipcode_98198  zipcode_98199  zipcode_nan  \\\n",
       "0            1.0            0.0            0.0            0.0          0.0   \n",
       "1            0.0            0.0            0.0            0.0          0.0   \n",
       "2            0.0            0.0            0.0            0.0          0.0   \n",
       "3            0.0            0.0            0.0            0.0          0.0   \n",
       "4            0.0            0.0            0.0            0.0          0.0   \n",
       "\n",
       "   date_2015  date_nan  \n",
       "0        0.0       0.0  \n",
       "1        0.0       0.0  \n",
       "2        1.0       0.0  \n",
       "3        0.0       0.0  \n",
       "4        1.0       0.0  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = pd.concat([df_log_norm, df_ohe], axis=1)\n",
    "df_clean = df_clean.astype('float')\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that our log transformation has not introduced any nan values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.isna().sum().max()\n",
    "# 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate multi-collinearity and outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll generate a correlation matrix to return pairwise correlations and identify highly correlated predictors. We will want to be aware of these correlations as we narrow in on our primary predictors. We are interested in values with absolute values roughly between 0.75 (strong positive correlation) and 1 (perfect positive correlation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_log</th>\n",
       "      <th>bedrooms_log</th>\n",
       "      <th>bathrooms_log</th>\n",
       "      <th>sqft_living_log</th>\n",
       "      <th>sqft_lot_log</th>\n",
       "      <th>floors_log</th>\n",
       "      <th>sqft_above_log</th>\n",
       "      <th>sqft_basement_log</th>\n",
       "      <th>yr_built_log</th>\n",
       "      <th>yr_renovated_log</th>\n",
       "      <th>lat_log</th>\n",
       "      <th>long_log</th>\n",
       "      <th>sqft_living15_log</th>\n",
       "      <th>sqft_lot15_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>price_log</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.342850</td>\n",
       "      <td>0.520278</td>\n",
       "      <td>0.674802</td>\n",
       "      <td>0.138261</td>\n",
       "      <td>0.322991</td>\n",
       "      <td>0.586013</td>\n",
       "      <td>0.239489</td>\n",
       "      <td>0.078987</td>\n",
       "      <td>0.015088</td>\n",
       "      <td>0.449133</td>\n",
       "      <td>0.052609</td>\n",
       "      <td>0.607154</td>\n",
       "      <td>0.123710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms_log</th>\n",
       "      <td>0.342850</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.534008</td>\n",
       "      <td>0.648121</td>\n",
       "      <td>0.195969</td>\n",
       "      <td>0.213203</td>\n",
       "      <td>0.546713</td>\n",
       "      <td>0.194754</td>\n",
       "      <td>0.194530</td>\n",
       "      <td>0.034958</td>\n",
       "      <td>-0.026777</td>\n",
       "      <td>0.167481</td>\n",
       "      <td>0.425690</td>\n",
       "      <td>0.175649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms_log</th>\n",
       "      <td>0.520278</td>\n",
       "      <td>0.534008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.760764</td>\n",
       "      <td>0.084877</td>\n",
       "      <td>0.510644</td>\n",
       "      <td>0.683889</td>\n",
       "      <td>0.198207</td>\n",
       "      <td>0.532918</td>\n",
       "      <td>0.043528</td>\n",
       "      <td>0.011330</td>\n",
       "      <td>0.248056</td>\n",
       "      <td>0.570469</td>\n",
       "      <td>0.079120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_living_log</th>\n",
       "      <td>0.674802</td>\n",
       "      <td>0.648121</td>\n",
       "      <td>0.760764</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.325983</td>\n",
       "      <td>0.393568</td>\n",
       "      <td>0.864979</td>\n",
       "      <td>0.291526</td>\n",
       "      <td>0.348973</td>\n",
       "      <td>0.016344</td>\n",
       "      <td>0.038881</td>\n",
       "      <td>0.265309</td>\n",
       "      <td>0.746836</td>\n",
       "      <td>0.303058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_lot_log</th>\n",
       "      <td>0.138261</td>\n",
       "      <td>0.195969</td>\n",
       "      <td>0.084877</td>\n",
       "      <td>0.325983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.211802</td>\n",
       "      <td>0.318663</td>\n",
       "      <td>-0.008953</td>\n",
       "      <td>-0.004421</td>\n",
       "      <td>-0.026689</td>\n",
       "      <td>-0.149394</td>\n",
       "      <td>0.378088</td>\n",
       "      <td>0.363743</td>\n",
       "      <td>0.918665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 price_log  bedrooms_log  bathrooms_log  sqft_living_log  \\\n",
       "price_log         1.000000      0.342850       0.520278         0.674802   \n",
       "bedrooms_log      0.342850      1.000000       0.534008         0.648121   \n",
       "bathrooms_log     0.520278      0.534008       1.000000         0.760764   \n",
       "sqft_living_log   0.674802      0.648121       0.760764         1.000000   \n",
       "sqft_lot_log      0.138261      0.195969       0.084877         0.325983   \n",
       "\n",
       "                 sqft_lot_log  floors_log  sqft_above_log  sqft_basement_log  \\\n",
       "price_log            0.138261    0.322991        0.586013           0.239489   \n",
       "bedrooms_log         0.195969    0.213203        0.546713           0.194754   \n",
       "bathrooms_log        0.084877    0.510644        0.683889           0.198207   \n",
       "sqft_living_log      0.325983    0.393568        0.864979           0.291526   \n",
       "sqft_lot_log         1.000000   -0.211802        0.318663          -0.008953   \n",
       "\n",
       "                 yr_built_log  yr_renovated_log   lat_log  long_log  \\\n",
       "price_log            0.078987          0.015088  0.449133  0.052609   \n",
       "bedrooms_log         0.194530          0.034958 -0.026777  0.167481   \n",
       "bathrooms_log        0.532918          0.043528  0.011330  0.248056   \n",
       "sqft_living_log      0.348973          0.016344  0.038881  0.265309   \n",
       "sqft_lot_log        -0.004421         -0.026689 -0.149394  0.378088   \n",
       "\n",
       "                 sqft_living15_log  sqft_lot15_log  \n",
       "price_log                 0.607154        0.123710  \n",
       "bedrooms_log              0.425690        0.175649  \n",
       "bathrooms_log             0.570469        0.079120  \n",
       "sqft_living_log           0.746836        0.303058  \n",
       "sqft_lot_log              0.363743        0.918665  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_clean[cont_features].corr()).head() # Snapshot of correlation test results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this many predictor variables, it can be easier to visualize the correlations with a heat map. In the heat map below, we can identify relationships to explore in greater detail.\n",
    "\n",
    "Note the high positive correlation in pairs for which both variables relate to square footage: for example, sqft_above and sqft_living."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_heat_map(df, features):\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    sns.heatmap(df[features].corr(), center=0)\n",
    "\n",
    "generate_heat_map(df_clean, cont_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation matrix indicates an almost perfect (~0.91) relationship between sqft_lot15_log and sqft_lot_log. This makes sense, since we would expect lots within the same neighborhood to be opf similar size. Let's remove sqft_lot15_log and run the heat map analysis again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_col(df, col, features):\n",
    "    df.drop([col], axis=1, inplace=True)\n",
    "    features.remove(col)\n",
    "    \n",
    "remove_col(df_clean, 'sqft_lot15_log', cont_features)\n",
    "generate_heat_map(df_clean, cont_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better.\n",
    "\n",
    "We also can get a sense of the outliers in our data using boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_boxplot(df, cols):\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(25, 15))\n",
    "    axe = axes.ravel()\n",
    "\n",
    "    for i, xcol in enumerate(cols):\n",
    "        sns.boxplot(x=df[xcol], ax=axe[i])\n",
    "        \n",
    "plot_boxplot(df_clean, cont_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some experimentation removing outliers beyond three standard deviations, I've decided to keep the outliers. Housing prices vary widely, and outliers can provide us with meaningful information about luxury properties and similarly about dilapidated properties. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Preview the relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll get a feel for the general trends in our data by previewing the relationship between each continuous predictors and the outcome variable (price) in a scatter plot.\n",
    "\n",
    "In the below, we can already visually detect a strong positive correlation between price and sqft_living, bathrooms, sqft_living_above, sqft_basement and sqft_living15. Evidently, larger houses command higher prices.\n",
    "\n",
    "A weaker positive correlation is also visible between price and bedrooms. We can also see in a clear indication in sqft_basement and yr_renovated where we have replaced missing values with the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatterplot(df, cols, outcome):\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(25, 15))\n",
    "    axe = axes.ravel()\n",
    "\n",
    "    for i, xcol in enumerate(cols):\n",
    "        df.plot(kind='scatter', x=xcol, y=outcome, alpha=0.4, color='b', ax=axe[i])\n",
    "\n",
    "outcome = 'price_log'\n",
    "preds = [i for i in cont_features if i != outcome]\n",
    "plot_scatterplot(df_clean, preds, outcome)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Transform the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the training and test data subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_and_training(df, preds, outcome):\n",
    "\n",
    "    # Create X and y\n",
    "    y = df_clean[outcome]\n",
    "    X = df_clean[preds]\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "def get_ols(X, y):\n",
    "    results = sm.OLS(y, X).fit()\n",
    "    print(results.summary())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [i for i in df_clean.columns if i != outcome]\n",
    "    \n",
    "X_train, X_test, y_train, y_test = get_test_and_training(df, preds, outcome)\n",
    "\n",
    "result = get_ols(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the output, we now want to remove all features associated with a p-value greater than our alpha of 0.05. Let's isolate these feature names in an array called 'exclude' and then re-run the analysis with an updated predictor array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = [\n",
    "    'zipcode_98178',\n",
    "    'zipcode_98155',\n",
    "    'zipcode_98148',\n",
    "    'zipcode_98133',\n",
    "    'zipcode_98055',\n",
    "    'zipcode_98030',\n",
    "    'zipcode_98031',\n",
    "    'zipcode_98028',\n",
    "    'zipcode_98019',\n",
    "    'zipcode_98011',\n",
    "    'zipcode_98002',\n",
    "    'grade_3',\n",
    "    'view_nan',\n",
    "    'condition_nan',\n",
    "    'waterfront_nan',\n",
    "    'condition_4',\n",
    "    'zipcode_nan',\n",
    "    'date_nan'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [i for i in df_clean.columns if i not in exclude and i != outcome]\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_test_and_training(df, preds, outcome)\n",
    "\n",
    "result = get_ols(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Build a linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll fit the model using a simple linear regression classifier to establish a baseline r-squared value and evaluate the mean-squared errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "# Print R2 and MSE for training and test sets\n",
    "print('Training r^2:', linreg.score(X_train, y_train))\n",
    "print('Test r^2:', linreg.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, linreg.predict(X_train)))\n",
    "print('Test MSE:', mean_squared_error(y_test, linreg.predict(X_test)))\n",
    "\n",
    "# Training r^2: 0.8872475048229136\n",
    "# Test r^2: 0.8807761768707825\n",
    "# Training MSE: 0.1129412222332609\n",
    "# Test MSE: 0.11839812810173139"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neat! Not only are our r-squared values fairly high (0.887 and 0.881), but our mean-squared errors (0.113 and 0.118) do not differ significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Answering our questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each coefficient in the earlier OLS ouput reflects the effect of the corresponding feature on price when all other variables are held constant. (Note that the documentation does not indicate the what scaling have been used on the price column, and so \"sale price units\" is used in place of specific dollar amounts.)\n",
    "\n",
    "Now that the linear regression output has given us reason to feel confident in our model, we can finally tackle the questions we posed at the start of this notebook.\n",
    "\n",
    "For example, we see that Squarefoot living has a significant (but low to moderate) coefficient of 0.1785. We interpret this as: \"Each additional 1 squarefoot of living space yields a 0.1785 increase in sale price units.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the effect on sale price of classification as a low grade property?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lowest grade in our dataset is grade 4 (*\"Generally older low quality construction. Does not meet code.\"*). It's possible that grades 0-3 are not present in our dataset because such structures do not meet the minimum standards for sale in King County.\n",
    "\n",
    "* Grade 4 (coeff = -0.7861 ): Having a grade code of 4 yields a 0.7861 decrease in sale price units.\n",
    "\n",
    "I am surprised that the effect of a grade 4 classification is lower than that of a grade 5 *(\"Lower construction costs and workmanship. Small, simple design\")* clasification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) What is the effect on sale price of classification as a high condition property?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest condition included in our dataset and in the range of possible values is condition 5 *(Very good: \"Excellent maintenance and updating on home. Not a total renovation.\").\n",
    "\n",
    "* Condition 5 (coeff = 0.1305): Having a condition code of 5 yields a 0.1305 decrease in sale price units.\n",
    "\n",
    "Note that the lower conditions (condition 3, coeff = -0.0751; condition 2, coeff = -0.3391) predictably have the effect of decreasing the sale price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) What is the effect on sale price of having a waterfront?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should come as no surprise that properties with a waterfront view can command significantly better sale prices:\n",
    "\n",
    "* Waterfront_1 (coeff = 0.1305): Having a waterfront view yields a 0.891 increase in sale price units.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the patterns that emerge in the above analyses do not deviate from what a layman might expect to find in the housing market. Bigger, higher quality houses with attractive views tend to command higher sale prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources\n",
    "\n",
    "* Outliers: https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba, https://stackoverflow.com/questions/23199796/detect-and-exclude-outliers-in-pandas-data-frame\n",
    "\n",
    "* Log transformations: https://discuss.analyticsvidhya.com/t/methods-to-deal-with-zero-values-while-performing-log-transformation-of-variable/2431/2\n",
    "\n",
    "* OHE: https://towardsdatascience.com/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd\n",
    "\n",
    "* Stepwise regression: https://towardsdatascience.com/stepwise-regression-tutorial-in-python-ebf7c782c922\n",
    "\n",
    "* Interpreting coefficients: https://statisticsbyjim.com/regression/interpret-coefficients-p-values-regression/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
